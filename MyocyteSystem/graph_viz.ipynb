{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import config\n",
    "from Plotting.myplt import plot_lines,plot_lines_with_colors\n",
    "import tslearn\n",
    "from tslearn import clustering\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "from numba import jit\n",
    "from sklearn.cluster import DBSCAN, OPTICS,KMeans,AgglomerativeClustering\n",
    "from sklearn import mixture\n",
    "import networkx as nx\n",
    "import graph_layout\n",
    "from sklearn import manifold\n",
    "# matplotlib.use('TkAgg')\n",
    "\n",
    "import myocyte_de_config\n",
    "import config as config\n",
    "import numpy as np\n",
    "from myocyte_gen_des import F_vec\n",
    "from scipy.integrate import odeint\n",
    "from Plotting.myplt import *\n",
    "from aml.time_mesuarment import timeit\n",
    "from pprint import pprint as Print\n",
    "from matplotlib import collections as matcoll\n",
    "from numba import jit\n",
    "from ParsingSystem.parse_and_build import TableGenerator\n",
    "from sklearn import decomposition\n",
    "\n",
    "@jit(nopython=True)\n",
    "def code_distance(x1:np.array,x2:np.array):\n",
    "    d = 0\n",
    "    for i in range(len(x1)):\n",
    "        d += int(x1[i]!=x2[i])\n",
    "    return d/len(x1)\n",
    "\n",
    "def get_distance_matrix(X, metric):\n",
    "    N_ = len(X)\n",
    "    d_m = np.zeros(shape=(N_,N_))\n",
    "    for i in range(N_-1):\n",
    "        print('\\r{}/{}'.format(i,N_-2),end='')\n",
    "        for j in range(i+1,N_):\n",
    "            d_ = metric(X[i],X[j])\n",
    "            d_m[i][j] = d_\n",
    "            d_m[j][i] = d_\n",
    "    print('')\n",
    "    return d_m\n",
    "def get_all_distances(X, metric):\n",
    "    N_ = len(X)\n",
    "    distances_ = np.zeros(shape=(int(N_*(N_-1)/2),))\n",
    "    k_ = 0\n",
    "    for i in range(N_-1):\n",
    "        print('\\r{}/{}'.format(i,N_-2),end='')\n",
    "        for j in range(i+1,N_):\n",
    "            distances_[k_] = metric(X[i],X[j])\n",
    "            k_ += 1\n",
    "    print('')\n",
    "    return distances_\n",
    "def plot_float_distribution(data,fig_size=(4,3),title=''):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(fig_size[0],fig_size[1])\n",
    "    x = []\n",
    "    for i in range(len(data)):\n",
    "        if np.isnan(data[i]):\n",
    "            continue\n",
    "        else:\n",
    "            x.append(data[i])\n",
    "    u_vs = np.unique(x)\n",
    "\n",
    "    if len(x) == 0:\n",
    "        ax.set_title(title +' is empty data')\n",
    "    elif len(u_vs)==1:\n",
    "        ax.set_title(title + ' all data is repeated with value: {}'.format(u_vs[0]))\n",
    "    else:\n",
    "        x = np.asarray(x)\n",
    "        q25, q75 = np.percentile(x, [25, 75])\n",
    "        bins = 0\n",
    "        if q25==q75:\n",
    "            bins = np.minimum(100,len(u_vs))\n",
    "        else:\n",
    "            bin_width = 2 * (q75 - q25) * len(x) ** (-1 / 3)\n",
    "            bins = np.minimum(100, round((np.max(x) - np.min(x)) / bin_width))\n",
    "        nan_rate = np.sum(np.isnan(data))/len(data)\n",
    "        ax.set_title(title+'. n of unique values {}'.format(len(u_vs)))\n",
    "        ax.set_xlabel('nan rate {}'.format(nan_rate))\n",
    "        density,bins = np.histogram(x,bins=bins,density=True)\n",
    "        unity_density = density / density.sum()\n",
    "        widths = bins[:-1] - bins[1:]\n",
    "        ax.bar(bins[1:], unity_density,width=widths)\n",
    "\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load(r'/home/user/gr_lab/data/labels_after_clustering.txt')\n",
    "distances = get_all_distances(X,metric=code_distance)\n",
    "distance_matrix = get_distance_matrix(X,metric=code_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_float_distribution(distances)\n",
    "print(np.sort(distances)[:30])\n",
    "print(np.min(distances))\n",
    "print(np.percentile(distances,1))\n",
    "print(np.percentile(distances,2))\n",
    "print(np.percentile(distances,3))\n",
    "print(np.percentile(distances,4))\n",
    "print(np.percentile(distances,5))\n",
    "print(np.percentile(distances,25))\n",
    "print(np.percentile(distances,50))\n",
    "print(np.percentile(distances,75))\n",
    "print(np.percentile(distances,99))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_alg_ = OPTICS(min_samples=4,metric=code_distance)\n",
    "clustering_alg_.fit(X)\n",
    "clusters_labels_ = clustering_alg_.labels_\n",
    "unique_labels_ = np.unique(clusters_labels_)\n",
    "N_ = len(np.unique(clusters_labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N_)\n",
    "cmap = matplotlib.colors.ListedColormap(sns.color_palette(\"bright\", N_).as_hex())\n",
    "colors_ = []\n",
    "for i in range(len(clusters_labels_)):\n",
    "    label_ = clusters_labels_[i]\n",
    "    if label_ == -1: \n",
    "        colors_.append((1.0,1.0,1.0,0.0))\n",
    "    else:\n",
    "        colors_.append(cmap(label_))\n",
    "unique_labels_colors_ = []\n",
    "for i in range(len(unique_labels_)):\n",
    "    color_ = 0\n",
    "    if unique_labels_[i] == -1:\n",
    "        color_ = (1.0,1.0,1.0,0.0)\n",
    "    else:\n",
    "        color_ = cmap(unique_labels_[i])\n",
    "    unique_labels_colors_.append(color_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.sum(clusters_labels_==-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize clusters in plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_model = graph_layout.GraphOnAPlane(distance_matrix,size_of_output_space = 33)\n",
    "gr_model.fit()\n",
    "gr_model.plot_loss()\n",
    "positions = gr_model.get_pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduction_alg1 = manifold.TSNE(n_components=2)\n",
    "dim_reduction_alg2 = decomposition.PCA(n_components=2)\n",
    "positions_1 = dim_reduction_alg1.fit_transform(positions)\n",
    "positions_2 = dim_reduction_alg2.fit_transform(positions)\n",
    "N_ = len(positions)\n",
    "fig,ax1 = graph_layout.cluster_plot((5,5), positions_1, colors_of_points=colors_,color_for_labels=unique_labels_colors_,labels_for_colors=unique_labels_)\n",
    "fig,ax2 = graph_layout.cluster_plot((5,5), positions_2, colors_of_points=colors_,color_for_labels=unique_labels_colors_,labels_for_colors=unique_labels_)\n",
    "ax1.set_title('t-SNE')\n",
    "ax2.set_title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('./tmp_plot.png',dpi= 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot elements from clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(config.dataset_for_time_clustering_path)\n",
    "Theta = dataset['params']\n",
    "Y =  dataset['solutions']\n",
    "names = dataset['names']\n",
    "index_by_name = dataset['index_by_name']\n",
    "name_by_index = dataset['name_by_index']\n",
    "start_point = dataset['start_point']\n",
    "t_0 = dataset['t_0']\n",
    "t_end = dataset['t_end']\n",
    "tau = dataset['tau']\n",
    "to_new_y_name = torch.load(config.myocyte_map_from_old_y_name_to_new_name_dict_filename)\n",
    "print('Theta {}\\tY {}'.format(Theta.shape, Y.shape))\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(unique_labels_))):\n",
    "    label = unique_labels_[i]\n",
    "    # if label==-1:\n",
    "    #     continue\n",
    "    # get random example \n",
    "    examples_indexes = np.argwhere(clusters_labels_==label).flatten()\n",
    "    random_pos = np.random.randint(low=0,high=len(examples_indexes))\n",
    "    example_index = examples_indexes[random_pos]\n",
    "    print(label)\n",
    "    print(examples_indexes)\n",
    "    print(example_index)\n",
    "    example = Y[example_index,:,:]\n",
    "    params_vec = Theta[example_index]\n",
    "    # plot solutions \n",
    "    N_time = int((t_end-t_0)/tau)+1\n",
    "    time_grid = np.linspace(start=t_0, stop=t_end, num=N_time)\n",
    "    solutions = odeint(func=F_vec, y0=start_point, t=time_grid, args=(params_vec,), full_output=False)\n",
    "    fig = init_figure()\n",
    "    fig = plot_solutions(fig, solutions, time_grid, to_new_y_name)\n",
    "    FcarbTimeSeries = np.asarray([myocyte_de_config.F_carb(time_grid[i]) for i in range(len(time_grid))])\n",
    "    FfatTimeSeries = np.asarray([myocyte_de_config.F_fat(time_grid[i]) for i in range(len(time_grid))])\n",
    "    FprotTimeSeries = np.asarray([myocyte_de_config.F_prot(time_grid[i]) for i in range(len(time_grid))])\n",
    "    add_line_to_fig(fig, time_grid,FprotTimeSeries,'F_{prot}')\n",
    "    add_line_to_fig(fig, time_grid,FfatTimeSeries,'F_{fat}')\n",
    "    add_line_to_fig(fig, time_grid,FcarbTimeSeries,'F_{carb}')\n",
    "    fig.show()\n",
    "    save_fig_to_html(fig,path=config.myo_path_to_html,filename='solution_{}.html'.format(i))\n",
    "# label = unique_labels_[57]\n",
    "# examples_indexes = np.argwhere(clusters_labels_==label).flatten()\n",
    "# print(examples_indexes)\n",
    "# for ex_index in examples_indexes:\n",
    "#     example_index = ex_index\n",
    "#     example = Y[example_index,:,:]\n",
    "#     params_vec = Theta[example_index]\n",
    "#     # plot solutions \n",
    "#     N_time = int((t_end-t_0)/tau)+1\n",
    "#     time_grid = np.linspace(start=t_0, stop=t_end, num=N_time)\n",
    "#     solutions = odeint(func=F_vec, y0=start_point, t=time_grid, args=(params_vec,), full_output=False)\n",
    "#     fig = init_figure()\n",
    "#     fig = plot_solutions(fig, solutions, time_grid, to_new_y_name)\n",
    "#     FcarbTimeSeries = np.asarray([myocyte_de_config.F_carb(time_grid[i]) for i in range(len(time_grid))])\n",
    "#     FfatTimeSeries = np.asarray([myocyte_de_config.F_fat(time_grid[i]) for i in range(len(time_grid))])\n",
    "#     FprotTimeSeries = np.asarray([myocyte_de_config.F_prot(time_grid[i]) for i in range(len(time_grid))])\n",
    "#     add_line_to_fig(fig, time_grid,FprotTimeSeries,'F_{prot}')\n",
    "#     add_line_to_fig(fig, time_grid,FfatTimeSeries,'F_{fat}')\n",
    "#     add_line_to_fig(fig, time_grid,FcarbTimeSeries,'F_{carb}')\n",
    "#     fig.show()\n",
    "#     save_fig_to_html(fig,path=config.myo_path_to_html,filename='solution_{}.html'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
