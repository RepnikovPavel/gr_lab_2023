{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import config\n",
    "from Plotting.myplt import plot_lines,plot_lines_with_colors\n",
    "import tslearn\n",
    "from tslearn import clustering\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "from numba import jit\n",
    "from sklearn.cluster import DBSCAN, OPTICS\n",
    "import networkx as nx\n",
    "import graph_layout\n",
    "\n",
    "@jit(nopython=True)\n",
    "def code_distance(x1:np.array,x2:np.array):\n",
    "    d = 0\n",
    "    for i in range(len(x1)):\n",
    "        d += int(x1[i]!=x2[i])\n",
    "    return d/len(x1)\n",
    "\n",
    "def get_distance_matrix(X, metric):\n",
    "    N_ = len(X)\n",
    "    d_m = np.zeros(shape=(N_,N_))\n",
    "    for i in range(N_-1):\n",
    "        print('\\r{}/{}'.format(i,N_-2),end='')\n",
    "        for j in range(i+1,N_):\n",
    "            d_ = metric(X[i],X[j])\n",
    "            d_m[i][j] = d_\n",
    "            d_m[j][i] = d_\n",
    "    return d_m\n",
    "def get_all_distances(X, metric):\n",
    "    N_ = len(X)\n",
    "    distances_ = np.zeros(shape=(int(N_*(N_-1)/2),))\n",
    "    k_ = 0\n",
    "    for i in range(N_-1):\n",
    "        print('\\r{}/{}'.format(i,N_-2),end='')\n",
    "        for j in range(i+1,N_):\n",
    "            distances_[k_] = metric(X[i],X[j])\n",
    "            k_ += 1\n",
    "    return distances_\n",
    "\n",
    "def plot_float_distribution(data,fig_size=(4,3),title=''):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(fig_size[0],fig_size[1])\n",
    "    x = []\n",
    "    for i in range(len(data)):\n",
    "        if np.isnan(data[i]):\n",
    "            continue\n",
    "        else:\n",
    "            x.append(data[i])\n",
    "    u_vs = np.unique(x)\n",
    "\n",
    "    if len(x) == 0:\n",
    "        ax.set_title(title +' is empty data')\n",
    "    elif len(u_vs)==1:\n",
    "        ax.set_title(title + ' all data is repeated with value: {}'.format(u_vs[0]))\n",
    "    else:\n",
    "        x = np.asarray(x)\n",
    "        q25, q75 = np.percentile(x, [25, 75])\n",
    "        bins = 0\n",
    "        if q25==q75:\n",
    "            bins = np.minimum(100,len(u_vs))\n",
    "        else:\n",
    "            bin_width = 2 * (q75 - q25) * len(x) ** (-1 / 3)\n",
    "            bins = np.minimum(100, round((np.max(x) - np.min(x)) / bin_width))\n",
    "        nan_rate = np.sum(np.isnan(data))/len(data)\n",
    "        ax.set_title(title+'. n of unique values {}'.format(len(u_vs)))\n",
    "        ax.set_xlabel('nan rate {}'.format(nan_rate))\n",
    "        density,bins = np.histogram(x,bins=bins,density=True)\n",
    "        unity_density = density / density.sum()\n",
    "        widths = bins[:-1] - bins[1:]\n",
    "        ax.bar(bins[1:], unity_density,width=widths)\n",
    "\n",
    "    return fig,ax\n",
    "\n",
    "def get_best_K(data):\n",
    "    distances_to_centroids = []\n",
    "    sil_score = []\n",
    "    number_of_clusters = []\n",
    "    for K in tqdm(range(3,8)):\n",
    "        number_of_clusters.append(K)\n",
    "        kMeansModel = clustering.TimeSeriesKMeans(n_clusters=K,n_jobs=8,max_iter=10,metric='euclidean')\n",
    "        kMeansModel.fit(data)\n",
    "        distances_to_centroids.append(kMeansModel.inertia_)\n",
    "        sil_score.append(clustering.silhouette_score(data,kMeansModel.labels_,n_jobs=8,metric='euclidean'))\n",
    "    distances_to_centroids = np.array(distances_to_centroids)\n",
    "    sil_score = np.array(sil_score)\n",
    "\n",
    "    # n1 = 10\n",
    "    # segments_d = np.linspace(start= np.min(distances_to_centroids),stop=np.max(distances_to_centroids), num=n1+1)\n",
    "    # D_q = np.zeros(shape=(len(distances_to_centroids,)))\n",
    "    # for i in range(len(distances_to_centroids)):\n",
    "    #     for j in range(len(segments_d)-1):\n",
    "    #         if j == len(segments_d)-1:\n",
    "    #             if distances_to_centroids[i] >= segments_d[j] and distances_to_centroids[i] <= segments_d[j+1]:\n",
    "    #                 D_q[i] = n1 - j \n",
    "    #                 break \n",
    "    #         else:\n",
    "    #             if distances_to_centroids[i] >= segments_d[j] and distances_to_centroids[i] < segments_d[j+1]:\n",
    "    #                 D_q[i] = n1 - j \n",
    "    #                 break\n",
    "    D_q = distances_to_centroids\n",
    "    D_q = D_q / np.max(D_q)\n",
    "    D_q = 1.0-D_q\n",
    "    # dDdk = np.zeros(shape=(len(sil_score),))\n",
    "    # for i in range(len(sil_score)):\n",
    "    #     if i==0:\n",
    "    #         dDdk[i] = (distances_to_centroids[i+1]-distances_to_centroids[i])/(number_of_clusters[i+1]-number_of_clusters[i])\n",
    "    #     elif i== len(sil_score)-1:\n",
    "    #         dDdk[i] = (distances_to_centroids[i]-distances_to_centroids[i-1])/(number_of_clusters[i]-number_of_clusters[i-1])\n",
    "    #     else:\n",
    "    #         h1 = number_of_clusters[i+1]-number_of_clusters[i]\n",
    "    #         h2 = number_of_clusters[i-1]-number_of_clusters[i]\n",
    "    #         y_i_plus_1 = distances_to_centroids[i+1] \n",
    "    #         y_i = distances_to_centroids[i]\n",
    "    #         y_i_minus_1=  distances_to_centroids[i-1]\n",
    "    #         dDdk[i] = (h2*y_i_plus_1-h1*y_i_minus_1+ (h1-h2)*y_i)/(2*h1*h2)\n",
    "    # dDdk = np.abs(dDdk)\n",
    "    # dDdk = np.power(dDdk,-1)\n",
    "    # dDdk = dDdk/np.max(dDdk)\n",
    "\n",
    "    # fig,ax = plt.subplots(nrows=4,ncols=1)\n",
    "    # fig.set_size_inches(16,16)\n",
    "    # ax[0].plot(number_of_clusters, D_q)\n",
    "    # ax[0].set_title(r'$D_{quality} \\: scaled$')\n",
    "    # ax[0].set_xlabel('K')\n",
    "    # ax[0].set_xticks(number_of_clusters)\n",
    "\n",
    "    # ax[1].plot(number_of_clusters,distances_to_centroids)\n",
    "    # ax[1].set_title(r'$D$')\n",
    "    # ax[1].set_xlabel('K')\n",
    "    # ax[1].set_xticks(number_of_clusters)\n",
    "\n",
    "    # ax[2].plot(number_of_clusters,sil_score)\n",
    "    # ax[2].set_title('sil_score')\n",
    "    # ax[2].set_xlabel('K')\n",
    "    # ax[2].set_xticks(number_of_clusters)\n",
    "\n",
    "    # k_vec = np.array(number_of_clusters)\n",
    "    # K_loss = 1.0 - k_vec/np.max(k_vec)\n",
    "\n",
    "    # Q = np.zeros(shape=(len(sil_score,)))\n",
    "    # for i in range(len(sil_score)):\n",
    "    #     Q[i] = np.minimum(D_q[i],sil_score[i])*K_loss[i]   \n",
    "    # ax[3].plot(number_of_clusters,Q)\n",
    "    # ax[3].set_title(r'$Q$')\n",
    "    # ax[3].set_xlabel('K')\n",
    "    # ax[3].set_xticks(number_of_clusters)\n",
    "\n",
    "    k_vec = np.array(number_of_clusters)\n",
    "    K_loss = 1.0 - k_vec/np.max(k_vec)\n",
    "\n",
    "    Q = np.zeros(shape=(len(sil_score,)))\n",
    "    for i in range(len(sil_score)):\n",
    "        Q[i] = np.minimum(D_q[i],sil_score[i]) \n",
    "\n",
    "    best_k = number_of_clusters[np.argmax(Q)]\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(config.dataset_for_time_clustering_path)\n",
    "Theta = dataset['params']\n",
    "Y =  dataset['solutions']\n",
    "names = dataset['names']\n",
    "index_by_name = dataset['index_by_name']\n",
    "name_by_index = dataset['name_by_index']\n",
    "print('Theta {}\\tY {}'.format(Theta.shape, Y.shape))\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multivariate time series clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(Y)):\n",
    "#     for j in range(len(names)):\n",
    "#         a_ = np.min(Y[i,:,j])\n",
    "#         b_ = np.max(Y[i,:,j])\n",
    "#         Y_tilde = (Y[i,:,j]-a_)/(b_-a_)\n",
    "#         Y[i,:,j] = Y_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time series to series of differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_ = np.zeros(shape=(Y.shape[0],Y.shape[1]-1,Y.shape[2]))\n",
    "# for i in range(len(Y)):\n",
    "#     for j in range(len(names)):\n",
    "#         Y_tilde = np.diff(Y[i,:,j])\n",
    "#         Y_[i,:,j] = Y_tilde\n",
    "# Y = Y_\n",
    "# print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_labels = np.zeros(shape=(len(names),len(Y)), dtype=np.intc)\n",
    "best_k = np.zeros(shape=(len(names),))\n",
    "for i in range(len(names)):\n",
    "    print('{}/{}'.format(i+1, len(names)))\n",
    "    name_i = names[i]\n",
    "    data = Y[:,:,index_by_name[name_i]]\n",
    "    # K = get_best_K(data)\n",
    "    K = 7\n",
    "    kMeansModel = clustering.TimeSeriesKMeans(n_clusters=K,n_jobs=8,max_iter=100,metric='euclidean')\n",
    "    kMeansModel.fit(data)\n",
    "    labels_ = kMeansModel.labels_\n",
    "    unique_labels_ = np.unique(labels_)\n",
    "    object_labels[i] = labels_\n",
    "    best_k[i] = K\n",
    "    print('num of clusters {}'.format(len(unique_labels_)))\n",
    "    cmap = matplotlib.colors.ListedColormap(sns.color_palette(\"bright\", len(unique_labels_)).as_hex())\n",
    "    colors_ = [cmap(el) for el in labels_]\n",
    "    fig,ax = plot_lines_with_colors(data,title='$'+name_i+' \\: $',colors=['k' for j_ in range(len(data))], alpha = 0.1)\n",
    "    for cluster_index in range(K):\n",
    "        # print(kMeansModel.cluster_centers_[cluster_index])\n",
    "        # print(kMeansModel.cluster_centers_[cluster_index,:,0].flatten())\n",
    "        ax.plot(kMeansModel.cluster_centers_[cluster_index,:,0].flatten(),color=cmap(cluster_index),alpha=1.0,label= str(cluster_index))\n",
    "    ax.legend()\n",
    "    ax.set_ylabel('ммоль/литр')\n",
    "    ax.set_xlabel('мин')\n",
    "    ax.grid(which = \"both\")\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(which = \"minor\", bottom = False, left = False)\n",
    "    fig.savefig(fname='./to_pr/to_pr_{}.png'.format(i),dpi = 200)\n",
    "    # plot centroids \n",
    "    plt.show()\n",
    "    # raise SystemExit\n",
    "print(best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_labels = np.zeros(shape=(len(Y),len(names)),dtype=np.intc)\n",
    "for i in range(len(Y)):\n",
    "    object_code = np.zeros(shape=(len(names),),dtype=np.intc)\n",
    "    for j in range(len(names)):\n",
    "        object_code[j] = object_labels[j,i]\n",
    "    agg_labels[i] = object_code\n",
    "print('number of clusters {}'.format(len(np.unique(agg_labels,axis=0))))\n",
    "torch.save(agg_labels, r'/home/user/gr_lab/data/labels_after_clustering.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster labels with OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load(r'/home/user/gr_lab/data/labels_after_clustering.txt')\n",
    "distances = get_all_distances(X,metric=code_distance)\n",
    "plot_float_distribution(distances)\n",
    "distance_matrix = get_distance_matrix(X,metric=code_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_s = []\n",
    "number_of_clusters = []\n",
    "rate_of_unknown_objects = []\n",
    "for MIN_S in tqdm(range(2,20)):\n",
    "    clustering_alg = OPTICS(min_samples=MIN_S,metric=code_distance)\n",
    "    clustering_alg.fit(X)\n",
    "    clusters_labels = np.unique(clustering_alg.labels_)\n",
    "    number_of_clusters.append(len(clusters_labels))\n",
    "    min_s.append(MIN_S)\n",
    "    rate_of_unknown_objects.append(np.sum((clustering_alg.labels_ == -1))/len(clustering_alg.labels_))\n",
    "    # print('number of clusters {}'.format(len(clusters_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=3,ncols=1)\n",
    "fig.set_size_inches(16,30)\n",
    "ax[0].plot(min_s, number_of_clusters)\n",
    "ax[0].set_yticks(number_of_clusters)\n",
    "ax[0].set_xticks(min_s)\n",
    "ax[0].set_title('number_of_clusters(min samples)')\n",
    "\n",
    "ax[1].plot(min_s, rate_of_unknown_objects)\n",
    "ax[1].set_yticks(rate_of_unknown_objects)\n",
    "ax[1].set_xticks(min_s)\n",
    "ax[1].set_title('rate_of_unknown_objects(min samples)')\n",
    "\n",
    "N_q = 1.0 - number_of_clusters/np.max(number_of_clusters)\n",
    "R_q = 1.0 - rate_of_unknown_objects/np.max(rate_of_unknown_objects)\n",
    "Q_optics = np.minimum(N_q, R_q)\n",
    "ax[2].plot(min_s, Q_optics)\n",
    "ax[2].set_yticks(Q_optics)\n",
    "ax[2].set_xticks(min_s)\n",
    "ax[2].set_title('Q(min samples)')\n",
    "# Q_optics = np.zeros(shape=(len(min_s),))\n",
    "# for i in range(len(min_s)):\n",
    "    # Q_optics[i] = np.minimum(N_q[i],R_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_alg_ = OPTICS(min_samples=14,metric=code_distance)\n",
    "clustering_alg_.fit(X)\n",
    "clusters_labels_ = clustering_alg_.labels_\n",
    "unique_labels_ = np.unique(clusters_labels_)\n",
    "N_ = len(np.unique(clusters_labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N_)\n",
    "cmap = matplotlib.colors.ListedColormap(sns.color_palette(\"bright\", N_).as_hex())\n",
    "colors_ = []\n",
    "for i in range(len(clusters_labels_)):\n",
    "    label_ = clusters_labels_[i]\n",
    "    if label_ == -1: \n",
    "        colors_.append((0.0,0.0,0.0,1.0))\n",
    "    else:\n",
    "        colors_.append(cmap(label_))\n",
    "unique_labels_colors_ = []\n",
    "for i in range(len(unique_labels_)):\n",
    "    color_ = 0\n",
    "    if unique_labels_[i] == -1:\n",
    "        color_ = (0.0,0.0,0.0,1.0)\n",
    "    else:\n",
    "        color_ = cmap(unique_labels_[i])\n",
    "    unique_labels_colors_.append(color_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.sum(clusters_labels_==-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
